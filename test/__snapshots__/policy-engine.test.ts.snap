// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`Policy Engine Integration Tests > Clause Selection > should handle clause exclusions > clause-exclusions 1`] = `
[
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "This policy establishes guidelines for the responsible use of artificial intelligence (AI) tools and systems within [ORGANIZATION_NAME]. It applies to all faculty, staff, students, and contractors who access, use, or implement AI technologies in educational, research, or administrative contexts.",
    "id": "purpose-001",
    "jurisdictions": [
      "US",
      "CA",
      "EU",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 1,
    "reason": "Specifically designed for k12 institutions; Applicable to restricted tool use policy; High relevance to your policy context",
    "riskLevel": "low",
    "selected": true,
    "tags": [
      "purpose",
      "scope",
      "definitions",
    ],
    "title": "Purpose and Scope",
    "toolUseModes": [
      "prohibited",
      "restricted",
      "permitted",
      "encouraged",
    ],
  },
  {
    "audience": [
      "k12",
    ],
    "body": "This policy governs the use of AI technologies in K-12 educational settings to ensure student safety, privacy protection under COPPA, and educational appropriateness. All AI implementations must support pedagogical goals while maintaining compliance with federal and state education regulations.",
    "id": "purpose-002-k12",
    "jurisdictions": [
      "US",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 2,
    "reason": "Matches medium risk profile; Specifically designed for k12 institutions; Applicable to restricted tool use policy; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "purpose",
      "k12",
      "coppa",
      "education",
    ],
    "title": "K-12 Educational Purpose",
    "toolUseModes": [
      "restricted",
      "permitted",
    ],
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "Artificial Intelligence (AI) refers to computer systems that can perform tasks typically requiring human intelligence, including but not limited to machine learning, natural language processing, computer vision, automated decision-making, and predictive analytics.",
    "id": "definitions-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 3,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "low",
    "selected": true,
    "tags": [
      "definitions",
      "ai",
      "technology",
    ],
    "title": "Artificial Intelligence Definition",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "High-Risk AI Systems are those that pose significant potential for adverse impact on student welfare, educational outcomes, privacy rights, or institutional operations. This includes AI systems used for student assessment, disciplinary decisions, college admissions, or processing of sensitive personal data.",
    "id": "definitions-002",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 4,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "definitions",
      "high-risk",
      "assessment",
    ],
    "title": "High-Risk AI System Definition",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "An AI Governance Committee shall be established comprising representatives from IT, Academic Affairs, Legal, Privacy, and Student Services. The committee shall review AI implementations, approve high-risk AI systems, and ensure ongoing compliance with this policy.",
    "dependencies": [
      "definitions-002",
    ],
    "id": "governance-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 5,
    "reason": "Matches medium risk profile; Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "governance",
      "committee",
      "oversight",
    ],
    "title": "AI Governance Committee",
  },
  {
    "audience": [
      "k12",
    ],
    "body": "Parents and guardians must be notified when AI systems will be used in educational activities involving their children. For AI systems that collect, use, or store student data, written parental consent must be obtained in compliance with COPPA requirements.",
    "id": "governance-002-k12",
    "jurisdictions": [
      "US",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 6,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "governance",
      "k12",
      "coppa",
      "parental-consent",
    ],
    "title": "K-12 Parental Notification",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems that process student educational records must comply with FERPA requirements. Student data shall not be used for AI training without explicit consent, and all data processing must be limited to legitimate educational purposes.",
    "id": "privacy-001",
    "jurisdictions": [
      "US",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 7,
    "reason": "Specifically designed for k12 institutions; Applicable to restricted tool use policy; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "privacy",
      "ferpa",
      "student-data",
    ],
    "title": "Student Data Protection",
    "toolUseModes": [
      "restricted",
      "permitted",
    ],
  },
  {
    "audience": [
      "k12",
    ],
    "body": "AI systems used with students under 13 years of age must comply with the Children's Online Privacy Protection Act (COPPA). This includes obtaining verifiable parental consent before collecting personal information and limiting data collection to what is necessary for the educational purpose.",
    "id": "privacy-002-coppa",
    "jurisdictions": [
      "US",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 8,
    "reason": "Specifically designed for k12 institutions; Applicable to restricted tool use policy; High relevance to your policy context",
    "riskLevel": "critical",
    "selected": true,
    "tags": [
      "privacy",
      "coppa",
      "k12",
      "children",
    ],
    "title": "COPPA Compliance for Under-13 Students",
    "toolUseModes": [
      "restricted",
    ],
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "All AI implementations must undergo a risk assessment prior to deployment. The assessment shall evaluate potential impacts on privacy, bias, accuracy, transparency, and educational outcomes. High-risk AI systems require additional review and approval.",
    "dependencies": [
      "definitions-002",
      "governance-001",
    ],
    "id": "risk-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 9,
    "reason": "Matches medium risk profile; Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "risk-assessment",
      "compliance",
      "approval",
    ],
    "title": "AI Risk Assessment Requirement",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems must be designed and implemented to minimize bias and ensure fair treatment of all students regardless of race, gender, ethnicity, disability status, or socioeconomic background. Regular bias testing and mitigation measures are required.",
    "id": "bias-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 10,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "bias",
      "fairness",
      "equity",
      "testing",
    ],
    "title": "AI Bias Prevention",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "Students and faculty must disclose the use of AI tools in academic work when required by course policies or institutional guidelines. AI-generated content must be clearly identified, and students remain responsible for the accuracy and originality of their submitted work.",
    "id": "integrity-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 11,
    "reason": "Matches medium risk profile; Specifically designed for k12 institutions; Applicable to restricted tool use policy; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "academic-integrity",
      "disclosure",
      "transparency",
    ],
    "title": "Academic Integrity and AI Use",
    "toolUseModes": [
      "restricted",
      "permitted",
    ],
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems shall be continuously monitored for performance, bias, and compliance with institutional policies. Regular audits, impact assessments, and user feedback collection are required to ensure ongoing effectiveness and safety.",
    "dependencies": [
      "governance-001",
    ],
    "id": "monitoring-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 12,
    "reason": "Matches medium risk profile; Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "monitoring",
      "auditing",
      "compliance",
    ],
    "title": "AI System Monitoring",
  },
]
`;

exports[`Policy Engine Integration Tests > Clause Selection > should handle low risk encouraged mode > k12-low-risk-encouraged 1`] = `
[
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "This policy establishes guidelines for the responsible use of artificial intelligence (AI) tools and systems within [ORGANIZATION_NAME]. It applies to all faculty, staff, students, and contractors who access, use, or implement AI technologies in educational, research, or administrative contexts.",
    "id": "purpose-001",
    "jurisdictions": [
      "US",
      "CA",
      "EU",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 1,
    "reason": "Matches low risk profile; Specifically designed for k12 institutions; Applicable to encouraged tool use policy; High relevance to your policy context",
    "riskLevel": "low",
    "selected": true,
    "tags": [
      "purpose",
      "scope",
      "definitions",
    ],
    "title": "Purpose and Scope",
    "toolUseModes": [
      "prohibited",
      "restricted",
      "permitted",
      "encouraged",
    ],
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "Artificial Intelligence (AI) refers to computer systems that can perform tasks typically requiring human intelligence, including but not limited to machine learning, natural language processing, computer vision, automated decision-making, and predictive analytics.",
    "id": "definitions-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 2,
    "reason": "Matches low risk profile; Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "low",
    "selected": true,
    "tags": [
      "definitions",
      "ai",
      "technology",
    ],
    "title": "Artificial Intelligence Definition",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "High-Risk AI Systems are those that pose significant potential for adverse impact on student welfare, educational outcomes, privacy rights, or institutional operations. This includes AI systems used for student assessment, disciplinary decisions, college admissions, or processing of sensitive personal data.",
    "id": "definitions-002",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 3,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "definitions",
      "high-risk",
      "assessment",
    ],
    "title": "High-Risk AI System Definition",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "An AI Governance Committee shall be established comprising representatives from IT, Academic Affairs, Legal, Privacy, and Student Services. The committee shall review AI implementations, approve high-risk AI systems, and ensure ongoing compliance with this policy.",
    "dependencies": [
      "definitions-002",
    ],
    "id": "governance-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 4,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "governance",
      "committee",
      "oversight",
    ],
    "title": "AI Governance Committee",
  },
  {
    "audience": [
      "k12",
    ],
    "body": "Parents and guardians must be notified when AI systems will be used in educational activities involving their children. For AI systems that collect, use, or store student data, written parental consent must be obtained in compliance with COPPA requirements.",
    "id": "governance-002-k12",
    "jurisdictions": [
      "US",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 5,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "governance",
      "k12",
      "coppa",
      "parental-consent",
    ],
    "title": "K-12 Parental Notification",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "All AI implementations must undergo a risk assessment prior to deployment. The assessment shall evaluate potential impacts on privacy, bias, accuracy, transparency, and educational outcomes. High-risk AI systems require additional review and approval.",
    "dependencies": [
      "definitions-002",
      "governance-001",
    ],
    "id": "risk-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 6,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "risk-assessment",
      "compliance",
      "approval",
    ],
    "title": "AI Risk Assessment Requirement",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems must be designed and implemented to minimize bias and ensure fair treatment of all students regardless of race, gender, ethnicity, disability status, or socioeconomic background. Regular bias testing and mitigation measures are required.",
    "id": "bias-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 7,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "bias",
      "fairness",
      "equity",
      "testing",
    ],
    "title": "AI Bias Prevention",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "Third-party AI vendors must demonstrate compliance with applicable privacy laws, security standards, and educational regulations. Vendor agreements must include data processing addendums, liability provisions, and audit rights.",
    "id": "vendor-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 8,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "vendor",
      "procurement",
      "compliance",
    ],
    "title": "AI Vendor Due Diligence",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "All users of AI systems must complete appropriate training on AI ethics, privacy implications, and institutional policies before gaining access. Training shall be updated annually and include emerging best practices.",
    "id": "training-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 9,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "training",
      "education",
      "competency",
    ],
    "title": "AI Training Requirements",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems shall be continuously monitored for performance, bias, and compliance with institutional policies. Regular audits, impact assessments, and user feedback collection are required to ensure ongoing effectiveness and safety.",
    "dependencies": [
      "governance-001",
    ],
    "id": "monitoring-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 10,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "monitoring",
      "auditing",
      "compliance",
    ],
    "title": "AI System Monitoring",
  },
]
`;

exports[`Policy Engine Integration Tests > Clause Selection > should respect clause dependencies > dependency-resolution 1`] = `
[
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "This policy establishes guidelines for the responsible use of artificial intelligence (AI) tools and systems within [ORGANIZATION_NAME]. It applies to all faculty, staff, students, and contractors who access, use, or implement AI technologies in educational, research, or administrative contexts.",
    "id": "purpose-001",
    "jurisdictions": [
      "US",
      "CA",
      "EU",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 1,
    "reason": "Specifically designed for highered institutions; Applicable to restricted tool use policy; High relevance to your policy context",
    "riskLevel": "low",
    "selected": true,
    "tags": [
      "purpose",
      "scope",
      "definitions",
    ],
    "title": "Purpose and Scope",
    "toolUseModes": [
      "prohibited",
      "restricted",
      "permitted",
      "encouraged",
    ],
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "Artificial Intelligence (AI) refers to computer systems that can perform tasks typically requiring human intelligence, including but not limited to machine learning, natural language processing, computer vision, automated decision-making, and predictive analytics.",
    "id": "definitions-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 2,
    "reason": "Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "low",
    "selected": true,
    "tags": [
      "definitions",
      "ai",
      "technology",
    ],
    "title": "Artificial Intelligence Definition",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "High-Risk AI Systems are those that pose significant potential for adverse impact on student welfare, educational outcomes, privacy rights, or institutional operations. This includes AI systems used for student assessment, disciplinary decisions, college admissions, or processing of sensitive personal data.",
    "id": "definitions-002",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 3,
    "reason": "Matches high risk profile; Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "definitions",
      "high-risk",
      "assessment",
    ],
    "title": "High-Risk AI System Definition",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "An AI Governance Committee shall be established comprising representatives from IT, Academic Affairs, Legal, Privacy, and Student Services. The committee shall review AI implementations, approve high-risk AI systems, and ensure ongoing compliance with this policy.",
    "dependencies": [
      "definitions-002",
    ],
    "id": "governance-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 4,
    "reason": "Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "governance",
      "committee",
      "oversight",
    ],
    "title": "AI Governance Committee",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems that process student educational records must comply with FERPA requirements. Student data shall not be used for AI training without explicit consent, and all data processing must be limited to legitimate educational purposes.",
    "id": "privacy-001",
    "jurisdictions": [
      "US",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 5,
    "reason": "Matches high risk profile; Specifically designed for highered institutions; Applicable to restricted tool use policy; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "privacy",
      "ferpa",
      "student-data",
    ],
    "title": "Student Data Protection",
    "toolUseModes": [
      "restricted",
      "permitted",
    ],
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "All AI implementations must undergo a risk assessment prior to deployment. The assessment shall evaluate potential impacts on privacy, bias, accuracy, transparency, and educational outcomes. High-risk AI systems require additional review and approval.",
    "dependencies": [
      "definitions-002",
      "governance-001",
    ],
    "id": "risk-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 6,
    "reason": "Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "risk-assessment",
      "compliance",
      "approval",
    ],
    "title": "AI Risk Assessment Requirement",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems must be designed and implemented to minimize bias and ensure fair treatment of all students regardless of race, gender, ethnicity, disability status, or socioeconomic background. Regular bias testing and mitigation measures are required.",
    "id": "bias-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 7,
    "reason": "Matches high risk profile; Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "bias",
      "fairness",
      "equity",
      "testing",
    ],
    "title": "AI Bias Prevention",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "Students and faculty must disclose the use of AI tools in academic work when required by course policies or institutional guidelines. AI-generated content must be clearly identified, and students remain responsible for the accuracy and originality of their submitted work.",
    "id": "integrity-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 8,
    "reason": "Specifically designed for highered institutions; Applicable to restricted tool use policy; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "academic-integrity",
      "disclosure",
      "transparency",
    ],
    "title": "Academic Integrity and AI Use",
    "toolUseModes": [
      "restricted",
      "permitted",
    ],
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "Third-party AI vendors must demonstrate compliance with applicable privacy laws, security standards, and educational regulations. Vendor agreements must include data processing addendums, liability provisions, and audit rights.",
    "id": "vendor-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 9,
    "reason": "Matches high risk profile; Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "vendor",
      "procurement",
      "compliance",
    ],
    "title": "AI Vendor Due Diligence",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "All users of AI systems must complete appropriate training on AI ethics, privacy implications, and institutional policies before gaining access. Training shall be updated annually and include emerging best practices.",
    "id": "training-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 10,
    "reason": "Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "training",
      "education",
      "competency",
    ],
    "title": "AI Training Requirements",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems shall be continuously monitored for performance, bias, and compliance with institutional policies. Regular audits, impact assessments, and user feedback collection are required to ensure ongoing effectiveness and safety.",
    "dependencies": [
      "governance-001",
    ],
    "id": "monitoring-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 11,
    "reason": "Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "monitoring",
      "auditing",
      "compliance",
    ],
    "title": "AI System Monitoring",
  },
]
`;

exports[`Policy Engine Integration Tests > Clause Selection > should select appropriate clauses for Higher Ed permitted mode > highered-permitted-clauses 1`] = `
[
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "This policy establishes guidelines for the responsible use of artificial intelligence (AI) tools and systems within [ORGANIZATION_NAME]. It applies to all faculty, staff, students, and contractors who access, use, or implement AI technologies in educational, research, or administrative contexts.",
    "id": "purpose-001",
    "jurisdictions": [
      "US",
      "CA",
      "EU",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 1,
    "reason": "Specifically designed for highered institutions; Applicable to permitted tool use policy; High relevance to your policy context",
    "riskLevel": "low",
    "selected": true,
    "tags": [
      "purpose",
      "scope",
      "definitions",
    ],
    "title": "Purpose and Scope",
    "toolUseModes": [
      "prohibited",
      "restricted",
      "permitted",
      "encouraged",
    ],
  },
  {
    "audience": [
      "highered",
    ],
    "body": "This policy facilitates responsible AI adoption in higher education research, instruction, and administration while ensuring compliance with FERPA, research ethics standards, and institutional academic integrity policies. AI use must advance educational and research missions while protecting student and research data.",
    "id": "purpose-003-highered",
    "jurisdictions": [
      "US",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 2,
    "reason": "Matches medium risk profile; Specifically designed for highered institutions; Applicable to permitted tool use policy; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "purpose",
      "highered",
      "ferpa",
      "research",
    ],
    "title": "Higher Education Research and Academic Purpose",
    "toolUseModes": [
      "permitted",
      "encouraged",
    ],
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "Artificial Intelligence (AI) refers to computer systems that can perform tasks typically requiring human intelligence, including but not limited to machine learning, natural language processing, computer vision, automated decision-making, and predictive analytics.",
    "id": "definitions-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 3,
    "reason": "Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "low",
    "selected": true,
    "tags": [
      "definitions",
      "ai",
      "technology",
    ],
    "title": "Artificial Intelligence Definition",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "High-Risk AI Systems are those that pose significant potential for adverse impact on student welfare, educational outcomes, privacy rights, or institutional operations. This includes AI systems used for student assessment, disciplinary decisions, college admissions, or processing of sensitive personal data.",
    "id": "definitions-002",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 4,
    "reason": "Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "definitions",
      "high-risk",
      "assessment",
    ],
    "title": "High-Risk AI System Definition",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "An AI Governance Committee shall be established comprising representatives from IT, Academic Affairs, Legal, Privacy, and Student Services. The committee shall review AI implementations, approve high-risk AI systems, and ensure ongoing compliance with this policy.",
    "dependencies": [
      "definitions-002",
    ],
    "id": "governance-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 5,
    "reason": "Matches medium risk profile; Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "governance",
      "committee",
      "oversight",
    ],
    "title": "AI Governance Committee",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems that process student educational records must comply with FERPA requirements. Student data shall not be used for AI training without explicit consent, and all data processing must be limited to legitimate educational purposes.",
    "id": "privacy-001",
    "jurisdictions": [
      "US",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 6,
    "reason": "Specifically designed for highered institutions; Applicable to permitted tool use policy; High relevance to your policy context; Addresses: privacy",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "privacy",
      "ferpa",
      "student-data",
    ],
    "title": "Student Data Protection",
    "toolUseModes": [
      "restricted",
      "permitted",
    ],
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "All AI implementations must undergo a risk assessment prior to deployment. The assessment shall evaluate potential impacts on privacy, bias, accuracy, transparency, and educational outcomes. High-risk AI systems require additional review and approval.",
    "dependencies": [
      "definitions-002",
      "governance-001",
    ],
    "id": "risk-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 7,
    "reason": "Matches medium risk profile; Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "risk-assessment",
      "compliance",
      "approval",
    ],
    "title": "AI Risk Assessment Requirement",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems must be designed and implemented to minimize bias and ensure fair treatment of all students regardless of race, gender, ethnicity, disability status, or socioeconomic background. Regular bias testing and mitigation measures are required.",
    "id": "bias-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 8,
    "reason": "Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "bias",
      "fairness",
      "equity",
      "testing",
    ],
    "title": "AI Bias Prevention",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "Students and faculty must disclose the use of AI tools in academic work when required by course policies or institutional guidelines. AI-generated content must be clearly identified, and students remain responsible for the accuracy and originality of their submitted work.",
    "id": "integrity-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 9,
    "reason": "Matches medium risk profile; Specifically designed for highered institutions; Applicable to permitted tool use policy; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "academic-integrity",
      "disclosure",
      "transparency",
    ],
    "title": "Academic Integrity and AI Use",
    "toolUseModes": [
      "restricted",
      "permitted",
    ],
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "Third-party AI vendors must demonstrate compliance with applicable privacy laws, security standards, and educational regulations. Vendor agreements must include data processing addendums, liability provisions, and audit rights.",
    "id": "vendor-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 10,
    "reason": "Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "vendor",
      "procurement",
      "compliance",
    ],
    "title": "AI Vendor Due Diligence",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "All users of AI systems must complete appropriate training on AI ethics, privacy implications, and institutional policies before gaining access. Training shall be updated annually and include emerging best practices.",
    "id": "training-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 11,
    "reason": "Matches medium risk profile; Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "training",
      "education",
      "competency",
    ],
    "title": "AI Training Requirements",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems shall be continuously monitored for performance, bias, and compliance with institutional policies. Regular audits, impact assessments, and user feedback collection are required to ensure ongoing effectiveness and safety.",
    "dependencies": [
      "governance-001",
    ],
    "id": "monitoring-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 12,
    "reason": "Matches medium risk profile; Specifically designed for highered institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "monitoring",
      "auditing",
      "compliance",
    ],
    "title": "AI System Monitoring",
  },
]
`;

exports[`Policy Engine Integration Tests > Clause Selection > should select appropriate clauses for K-12 prohibited mode > k12-prohibited-clauses 1`] = `
[
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "This policy establishes guidelines for the responsible use of artificial intelligence (AI) tools and systems within [ORGANIZATION_NAME]. It applies to all faculty, staff, students, and contractors who access, use, or implement AI technologies in educational, research, or administrative contexts.",
    "id": "purpose-001",
    "jurisdictions": [
      "US",
      "CA",
      "EU",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 1,
    "reason": "Specifically designed for k12 institutions; Applicable to prohibited tool use policy; Includes CA jurisdiction requirements; High relevance to your policy context",
    "riskLevel": "low",
    "selected": true,
    "tags": [
      "purpose",
      "scope",
      "definitions",
    ],
    "title": "Purpose and Scope",
    "toolUseModes": [
      "prohibited",
      "restricted",
      "permitted",
      "encouraged",
    ],
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "Artificial Intelligence (AI) refers to computer systems that can perform tasks typically requiring human intelligence, including but not limited to machine learning, natural language processing, computer vision, automated decision-making, and predictive analytics.",
    "id": "definitions-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 2,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "low",
    "selected": true,
    "tags": [
      "definitions",
      "ai",
      "technology",
    ],
    "title": "Artificial Intelligence Definition",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "High-Risk AI Systems are those that pose significant potential for adverse impact on student welfare, educational outcomes, privacy rights, or institutional operations. This includes AI systems used for student assessment, disciplinary decisions, college admissions, or processing of sensitive personal data.",
    "id": "definitions-002",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 3,
    "reason": "Matches high risk profile; Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "definitions",
      "high-risk",
      "assessment",
    ],
    "title": "High-Risk AI System Definition",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "An AI Governance Committee shall be established comprising representatives from IT, Academic Affairs, Legal, Privacy, and Student Services. The committee shall review AI implementations, approve high-risk AI systems, and ensure ongoing compliance with this policy.",
    "dependencies": [
      "definitions-002",
    ],
    "id": "governance-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 4,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "governance",
      "committee",
      "oversight",
    ],
    "title": "AI Governance Committee",
  },
  {
    "audience": [
      "k12",
    ],
    "body": "Parents and guardians must be notified when AI systems will be used in educational activities involving their children. For AI systems that collect, use, or store student data, written parental consent must be obtained in compliance with COPPA requirements.",
    "id": "governance-002-k12",
    "jurisdictions": [
      "US",
    ],
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 5,
    "reason": "Matches high risk profile; Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "governance",
      "k12",
      "coppa",
      "parental-consent",
    ],
    "title": "K-12 Parental Notification",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "All AI implementations must undergo a risk assessment prior to deployment. The assessment shall evaluate potential impacts on privacy, bias, accuracy, transparency, and educational outcomes. High-risk AI systems require additional review and approval.",
    "dependencies": [
      "definitions-002",
      "governance-001",
    ],
    "id": "risk-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 6,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "risk-assessment",
      "compliance",
      "approval",
    ],
    "title": "AI Risk Assessment Requirement",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems must be designed and implemented to minimize bias and ensure fair treatment of all students regardless of race, gender, ethnicity, disability status, or socioeconomic background. Regular bias testing and mitigation measures are required.",
    "id": "bias-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 7,
    "reason": "Matches high risk profile; Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "bias",
      "fairness",
      "equity",
      "testing",
    ],
    "title": "AI Bias Prevention",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "Third-party AI vendors must demonstrate compliance with applicable privacy laws, security standards, and educational regulations. Vendor agreements must include data processing addendums, liability provisions, and audit rights.",
    "id": "vendor-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 8,
    "reason": "Matches high risk profile; Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "high",
    "selected": true,
    "tags": [
      "vendor",
      "procurement",
      "compliance",
    ],
    "title": "AI Vendor Due Diligence",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems shall not be used for: (1) Automated disciplinary decisions without human review, (2) Surveillance of students beyond legitimate safety purposes, (3) Predictive analytics that could result in discriminatory treatment, (4) Processing of biometric data without explicit consent and legal basis.",
    "id": "prohibited-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 9,
    "reason": "Critical clause recommended for high-risk environment; Specifically designed for k12 institutions; Applicable to prohibited tool use policy; High relevance to your policy context",
    "riskLevel": "critical",
    "selected": true,
    "tags": [
      "prohibited",
      "restrictions",
      "surveillance",
    ],
    "title": "Prohibited AI Uses",
    "toolUseModes": [
      "prohibited",
    ],
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "All users of AI systems must complete appropriate training on AI ethics, privacy implications, and institutional policies before gaining access. Training shall be updated annually and include emerging best practices.",
    "id": "training-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 10,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "training",
      "education",
      "competency",
    ],
    "title": "AI Training Requirements",
  },
  {
    "audience": [
      "k12",
      "highered",
    ],
    "body": "AI systems shall be continuously monitored for performance, bias, and compliance with institutional policies. Regular audits, impact assessments, and user feedback collection are required to ensure ongoing effectiveness and safety.",
    "dependencies": [
      "governance-001",
    ],
    "id": "monitoring-001",
    "metadata": {
      "author": "Policy Engine",
      "createdAt": "2025-08-26T00:00:00Z",
      "legalReview": true,
      "updatedAt": "2025-08-26T00:00:00Z",
      "version": 1,
    },
    "priority": 11,
    "reason": "Specifically designed for k12 institutions; High relevance to your policy context",
    "riskLevel": "medium",
    "selected": true,
    "tags": [
      "monitoring",
      "auditing",
      "compliance",
    ],
    "title": "AI System Monitoring",
  },
]
`;

exports[`Policy Engine Integration Tests > Error Handling > should handle empty diff inputs > empty-diff 1`] = `[]`;

exports[`Policy Engine Integration Tests > Error Handling > should handle invalid clause selection inputs > invalid-input-clauses 1`] = `[]`;
